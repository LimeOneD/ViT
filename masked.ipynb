{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":73111,"databundleVersionId":8040143,"sourceType":"competition"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport random\nimport numpy as np \nimport csv\n\n\n\nimport torch\nfrom torch import nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import random_split\nfrom torchvision import datasets, transforms\n\n\nseed_value = 37\nnp.random.seed(seed_value)\ntorch.manual_seed(seed_value)\n\nLEARNING_RATE = 0.0001\nNUM_CLASSES = 50\nPATCH_SIZE = 16\nIMG_SIZE = 64\nIN_CHANNEL = 3\nEPOCHS = 100\nNUM_HEADS = 8\nDROPOUT = 0.01\nHIDDEN_DIM = 1024\nADAM_WEIGHT_DECAY = 0\nADAM_BETAS = (0.9, 0.999)\nACTIVATION = \"gelu\"\nNUM_ENCODERS = 6\nEMBED_DIM = (PATCH_SIZE **2) * IN_CHANNEL\nNUM_PATCHES = ( IMG_SIZE // PATCH_SIZE )**2\n\ndevice = \"cuda\"","metadata":{"execution":{"iopub.status.busy":"2024-04-28T06:16:55.451583Z","iopub.execute_input":"2024-04-28T06:16:55.452575Z","iopub.status.idle":"2024-04-28T06:16:55.461551Z","shell.execute_reply.started":"2024-04-28T06:16:55.452542Z","shell.execute_reply":"2024-04-28T06:16:55.460594Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class AddGaussianNoise(object):\n    def __init__(self, mean=0, std=1):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, tensor):\n        # Adding Gaussian noise\n        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n   \n    \ntransform1 = transforms.Compose([\n    transforms.Resize((64, 64)), \n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    AddGaussianNoise(mean=0, std=0.1),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    \n])\n\ntransform2 = transforms.Compose([\n    transforms.Resize((64, 64)),  \n    transforms.ToTensor(),          \n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  \n])\n\nroot_dir = \"/kaggle/input/iith-dl-contest-2024/train/train\"\nprediction_root_dir = \"/kaggle/input/iith-dl-contest-2024/test\"\n\ndataset = datasets.ImageFolder(root=root_dir, transform=transform1)\n\nval_size = int(0.1 * len(dataset))\ntrain_size = len(dataset) - val_size\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\nprediction_dataset = datasets.ImageFolder(root=prediction_root_dir, transform=transform2)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T06:16:55.463470Z","iopub.execute_input":"2024-04-28T06:16:55.463852Z","iopub.status.idle":"2024-04-28T06:18:15.217804Z","shell.execute_reply.started":"2024-04-28T06:16:55.463824Z","shell.execute_reply":"2024-04-28T06:18:15.216553Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class PatchImg(nn.Module):\n    def __init__(self, embed_dim, patch_size, num_patches, dropout, in_channels):\n        super().__init__()\n        self.patcher = nn.Sequential(\n            nn.Conv2d(\n                in_channels=in_channels,\n                out_channels=embed_dim,\n                kernel_size=patch_size,\n                stride=patch_size\n            ),\n            nn.Flatten(2))\n        self.cls_token = nn.Parameter(torch.rand(size=(1, in_channels, embed_dim)), requires_grad=True)\n        self.position_embedding = nn.Parameter(torch.rand(size=(1, num_patches + 3, embed_dim)), requires_grad=True)\n        self.dropout = nn.Dropout(p=dropout)\n        self.num_patches = num_patches\n\n    def forward(self, x, masking):\n        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n\n        x = self.patcher(x).permute(0, 2, 1)\n        x = torch.cat([cls_token, x], dim=1)\n\n        if masking:\n            # Generate random mask during training\n            mask = torch.ones_like(x)\n            mask[:, :self.num_patches, :] = torch.randint(0, 2, size=(x.shape[0], self.num_patches, x.shape[-1]))\n            \n            # Fill removed patches with random noise\n            noise = torch.randn_like(x[:, :self.num_patches, :])\n            x[:, :self.num_patches, :] = x[:, :self.num_patches, :] * mask[:, :self.num_patches, :] + noise * (1 - mask[:, :self.num_patches, :])\n        else:\n            # During evaluation/testing, no masking is applied\n            mask = torch.ones_like(x)\n\n        x = self.position_embedding + x\n        x = self.dropout(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T06:33:02.682533Z","iopub.execute_input":"2024-04-28T06:33:02.682920Z","iopub.status.idle":"2024-04-28T06:33:02.694907Z","shell.execute_reply.started":"2024-04-28T06:33:02.682894Z","shell.execute_reply":"2024-04-28T06:33:02.693876Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"class PatchImg(nn.Module):\n    def __init__(self, embed_dim, patch_size, num_patches, dropout, in_channels):\n        super().__init__()\n        self.patcher = nn.Sequential(\n            nn.Conv2d(\n                in_channels = in_channels,\n                out_channels = embed_dim,\n                kernel_size=patch_size,\n                stride=patch_size\n            ),\n            nn.Flatten(2))\n        self.cls_token = nn.Parameter(torch.rand(size=(1, in_channels, embed_dim)), requires_grad=True)\n        self.position_embedding = nn.Parameter(torch.rand(size=(1, num_patches+3, embed_dim)), requires_grad=True)\n        self.dropout = nn.Dropout(p=dropout)\n\n    def forward(self, x):\n        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n\n        x=self.patcher(x).permute(0,2,1)\n        x=torch.cat([cls_token, x], dim=1)\n        #print(\"Position embedding size:\", self.position_embedding.size())\n        #print(\"x size before addition:\", x.size())\n        x=self.position_embedding + x\n        x=self.dropout(x)\n        return x\n        \n\n\"\"\"model = PatchImg(EMBED_DIM, PATCH_SIZE, NUM_PATCHES, DROPOUT, IN_CHANNEL).to(device)\nx=torch.randn(32, 1, 64, 64).to(device)\nprint(model(x).shape)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:30:38.687444Z","iopub.execute_input":"2024-04-27T06:30:38.687875Z","iopub.status.idle":"2024-04-27T06:30:38.701603Z","shell.execute_reply.started":"2024-04-27T06:30:38.687846Z","shell.execute_reply":"2024-04-27T06:30:38.700501Z"}}},{"cell_type":"code","source":"class ViT(nn.Module):\n    def __init__(self, num_patches, img_size, num_classes, patch_size, embed_dim, num_encoders, num_heads, hidden_dim,  dropout, activation, in_channels):\n        super().__init__()\n        self.embeddings_block = PatchImg(embed_dim, patch_size, num_patches, dropout, in_channels)\n\n        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, activation=activation, batch_first=True, norm_first=True)\n        self.encoder_blocks = nn.TransformerEncoder(encoder_layer, num_layers=num_encoders)\n\n        self.mlp_head = nn.Sequential(\n            nn.LayerNorm(normalized_shape=embed_dim),\n            nn.Linear(in_features=embed_dim, out_features=num_classes)\n        )\n\n    def forward(self, x, masking):\n        x = self.embeddings_block(x, masking)\n        x = self.encoder_blocks(x)\n        x = F.softmax(self.mlp_head(x[:, 0, :]))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-28T06:18:15.234074Z","iopub.execute_input":"2024-04-28T06:18:15.234384Z","iopub.status.idle":"2024-04-28T06:18:15.248939Z","shell.execute_reply.started":"2024-04-28T06:18:15.234335Z","shell.execute_reply":"2024-04-28T06:18:15.248016Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"class ViT(nn.Module):\n    def __init__(self, num_patches, img_size, num_classes, patch_size, embed_dim, num_encoders, num_heads, hidden_dim,  dropout, activation, in_channels):\n        super().__init__()\n        self.embeddings_block = PatchImg(embed_dim, patch_size, num_patches, dropout, in_channels)\n\n        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, activation=activation, batch_first=True, norm_first=True)\n        self.encoder_blocks = nn.TransformerEncoder(encoder_layer, num_layers=num_encoders)\n\n        self.mlp_head = nn.Sequential(\n            #nn.LayerNorm(normalized_shape=embed_dim),\n            nn.Linear( 14592, 4096),\n            nn.ReLU(),\n            nn.BatchNorm1d(4096),\n            \n            nn.Linear( 4096, 2048),\n            nn.ReLU(),\n            nn.BatchNorm1d(2048),\n            \n            nn.Linear(2048, 50),\n            nn.Softmax(dim=1)\n            \n        )\n\n    def forward(self, x):\n        x = self.embeddings_block(x)\n        x = self.encoder_blocks(x)\n        x = x.contiguous().view(50, -1)\n        x = self.mlp_head(x)\n        return x\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:30:42.123056Z","iopub.execute_input":"2024-04-27T06:30:42.123506Z","iopub.status.idle":"2024-04-27T06:30:42.133204Z","shell.execute_reply.started":"2024-04-27T06:30:42.123474Z","shell.execute_reply":"2024-04-27T06:30:42.132213Z"}}},{"cell_type":"markdown","source":"model = ViT(NUM_PATCHES, IMG_SIZE, NUM_CLASSES, PATCH_SIZE, EMBED_DIM, NUM_ENCODERS, NUM_HEADS, HIDDEN_DIM, DROPOUT, ACTIVATION, IN_CHANNEL).to(device)\n\nx = torch.randn(50, 3,64, 64).to(device)\nprint(model(x).shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:24:51.323688Z","iopub.execute_input":"2024-04-27T06:24:51.324608Z","iopub.status.idle":"2024-04-27T06:24:52.233121Z","shell.execute_reply.started":"2024-04-27T06:24:51.324570Z","shell.execute_reply":"2024-04-27T06:24:52.232109Z"}}},{"cell_type":"markdown","source":"device = \"cuda\"\n\nprint(sum(p.numel() for p in model.parameters() if p.requires_grad))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T05:52:56.113306Z","iopub.execute_input":"2024-04-27T05:52:56.114123Z","iopub.status.idle":"2024-04-27T05:52:56.119820Z","shell.execute_reply.started":"2024-04-27T05:52:56.114089Z","shell.execute_reply":"2024-04-27T05:52:56.118894Z"}}},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=50, shuffle=True, num_workers=2)\nval_dataloader = DataLoader(val_dataset, batch_size=50, shuffle=False, num_workers=2)\npredict_dataloader = DataLoader(prediction_dataset, batch_size=50, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T06:18:15.251440Z","iopub.execute_input":"2024-04-28T06:18:15.252099Z","iopub.status.idle":"2024-04-28T06:18:15.262562Z","shell.execute_reply.started":"2024-04-28T06:18:15.252064Z","shell.execute_reply":"2024-04-28T06:18:15.261606Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"for step, (inputs, labels) in enumerate(val_dataloader):\n    if(inputs.shape[1]!= 3 or inputs.shape[2]!=64 or inputs.shape[3]!=64):\n        print (\"hello\")\nprint(\"allOK\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:16:18.146700Z","iopub.execute_input":"2024-04-27T06:16:18.147057Z","iopub.status.idle":"2024-04-27T06:16:55.410345Z","shell.execute_reply.started":"2024-04-27T06:16:18.147030Z","shell.execute_reply":"2024-04-27T06:16:55.409170Z"}}},{"cell_type":"markdown","source":"\n\n    \n\nmodel = ViT(NUM_PATCHES, IMG_SIZE, NUM_CLASSES, PATCH_SIZE, EMBED_DIM, NUM_ENCODERS, NUM_HEADS, HIDDEN_DIM, DROPOUT, ACTIVATION, IN_CHANNEL).to(device)\n#model = torch.nn.DataParallel(model)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), betas=ADAM_BETAS, lr=LEARNING_RATE, weight_decay=ADAM_WEIGHT_DECAY)\n\n\n\nfor epoch in range(1):\n\n    model.eval()\n    val_labels = []\n    val_preds = []\n    val_running_loss = 0\n    with torch.no_grad():\n        for step, (inputs, labels) in enumerate(val_dataloader):\n            x = inputs.float().to(device) \n            y = labels.type(torch.uint8).to(device)\n\n            y_preds = model(x)\n            y_pred_labels = torch.argmax(y_preds, dim=1)\n\n            val_labels.extend(labels.cpu().detach())\n            val_preds.extend(y_pred_labels.cpu().detach())\n\n            loss = criterion(y_preds, y)\n\n            val_running_loss += loss.item()\n           \n\n    val_loss = val_running_loss / (step+1)\n\nprint(\"AllOK\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:26:59.063258Z","iopub.execute_input":"2024-04-27T06:26:59.064008Z","iopub.status.idle":"2024-04-27T06:27:09.900696Z","shell.execute_reply.started":"2024-04-27T06:26:59.063973Z","shell.execute_reply":"2024-04-27T06:27:09.899526Z"}}},{"cell_type":"code","source":"device = \"cuda\"\n#           num_patches, img_size, num_classes, patch_size, embed_dim, num_encoders, num_heads, hidden_dim,  dropout, activation, in_channels\nmodel = ViT(NUM_PATCHES, IMG_SIZE, NUM_CLASSES, PATCH_SIZE, EMBED_DIM, NUM_ENCODERS, NUM_HEADS, HIDDEN_DIM, DROPOUT, ACTIVATION, IN_CHANNEL).to(device)\n#model = torch.nn.DataParallel(model)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), betas=ADAM_BETAS, lr=LEARNING_RATE, weight_decay=ADAM_WEIGHT_DECAY)\n\nloss_log = [[\"training loss\", \"validation loss\", \"training accuracy\", \"validation accuracy\"]]\n\nfor epoch in range(EPOCHS):\n    model.train()\n    train_labels = []\n    train_preds = []\n    train_running_loss = 0\n    for step, (inputs, labels) in enumerate(train_dataloader):\n        x = inputs.float().to(device)\n        y = labels.type(torch.uint8).to(device)\n        y_preds = model(x, masking=True)\n        y_pred_labels = torch.argmax(y_preds, dim=1)\n\n        train_labels.extend(labels.cpu().detach())\n        train_preds.extend(y_pred_labels.cpu().detach())\n\n        loss = criterion(y_preds, y)\n        train_running_loss += loss.item()\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        \n\n    train_loss = train_running_loss / (step+1)\n\n    model.eval()\n    val_labels = []\n    val_preds = []\n    val_running_loss = 0\n    with torch.no_grad():\n        for step, (inputs, labels) in enumerate(val_dataloader):\n            x = inputs.float().to(device) \n            y = labels.type(torch.uint8).to(device)\n\n            y_preds = model(x, masking=False)\n            y_pred_labels = torch.argmax(y_preds, dim=1)\n\n            val_labels.extend(labels.cpu().detach())\n            val_preds.extend(y_pred_labels.cpu().detach())\n\n            loss = criterion(y_preds, y)\n\n            val_running_loss += loss.item()\n\n    val_loss = val_running_loss / (step+1)\n\n    print(\"-\"*40)\n    print(f\"Train Loss for epoch {epoch+1}: {train_loss:.4f}\")\n        \n    print(f\"Validation Loss for epoch {epoch+1}: {val_loss:.4f}\")\n        \n    train_acc = sum(1 for x,y in zip(train_preds, train_labels) if x==y) / len(train_labels)\n    print(f\"Train Accuracy for epoch {epoch+1}: {train_acc}\")\n        \n    val_acc = sum(1 for x,y in zip(val_preds, val_labels) if x==y )/ len(val_labels)\n    print(f\"Val Accuracy for epoch {epoch+1}: {val_acc}\")\n      \n    loss_log.append([float(f\"{train_loss:.4f}\"), float(f\"{val_loss:.4f}\"), float(f\"{train_acc:.4f}\"), float(f\"{val_acc:.4f}\")])\n        \n    if((epoch+1) % 5 == 0):\n        \n            \n        predictions = []\n        model.eval()\n        with torch.no_grad():\n            for inputs, _ in predict_dataloader:\n                x = inputs.float().to(device) \n                y = model(x, masking=False)\n                _, predicted = torch.max(y, 1)\n                predictions.extend(predicted.cpu().tolist())\n        class_names = [dataset.classes[idx] for idx in predictions]\n            \n            \n        data = [[\"ID\", \"Category\"]]\n\n        for i in range(len(class_names)):\n            data.append([f\"{i}.JPEG\", class_names[i]])\n        file_path = f\"ViT64_ep{epoch+1}-lr-001.csv\"\n        with open(file_path, 'w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerows(data)\n            \ntorch.save(model.state_dict(), f\"model_ViT_ep{epoch+1}.pth\")\nwith open(\"log_loss-vit-lr-001.csv\", 'w', newline='') as log:\n    writer = csv.writer(log)\n    writer.writerows(loss_log)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T06:33:08.498405Z","iopub.execute_input":"2024-04-28T06:33:08.499297Z","iopub.status.idle":"2024-04-28T12:49:50.793301Z","shell.execute_reply.started":"2024-04-28T06:33:08.499264Z","shell.execute_reply":"2024-04-28T12:49:50.791920Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/4166256205.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  x = F.softmax(self.mlp_head(x[:, 0, :]))\n","output_type":"stream"},{"name":"stdout","text":"----------------------------------------\nTrain Loss for epoch 1: 3.8776\nValidation Loss for epoch 1: 3.8707\nTrain Accuracy for epoch 1: 0.06557264957264958\nVal Accuracy for epoch 1: 0.072\n----------------------------------------\nTrain Loss for epoch 2: 3.8513\nValidation Loss for epoch 2: 3.8616\nTrain Accuracy for epoch 2: 0.09268376068376068\nVal Accuracy for epoch 2: 0.07953846153846154\n----------------------------------------\nTrain Loss for epoch 3: 3.8391\nValidation Loss for epoch 3: 3.8473\nTrain Accuracy for epoch 3: 0.10553846153846154\nVal Accuracy for epoch 3: 0.09461538461538462\n----------------------------------------\nTrain Loss for epoch 4: 3.8237\nValidation Loss for epoch 4: 3.8333\nTrain Accuracy for epoch 4: 0.12170940170940171\nVal Accuracy for epoch 4: 0.10892307692307693\n----------------------------------------\nTrain Loss for epoch 5: 3.8146\nValidation Loss for epoch 5: 3.8278\nTrain Accuracy for epoch 5: 0.13017094017094016\nVal Accuracy for epoch 5: 0.11723076923076924\n----------------------------------------\nTrain Loss for epoch 6: 3.8053\nValidation Loss for epoch 6: 3.8246\nTrain Accuracy for epoch 6: 0.13972649572649573\nVal Accuracy for epoch 6: 0.11923076923076924\n----------------------------------------\nTrain Loss for epoch 7: 3.7958\nValidation Loss for epoch 7: 3.8120\nTrain Accuracy for epoch 7: 0.14982905982905984\nVal Accuracy for epoch 7: 0.13353846153846155\n----------------------------------------\nTrain Loss for epoch 8: 3.7883\nValidation Loss for epoch 8: 3.8166\nTrain Accuracy for epoch 8: 0.15745299145299146\nVal Accuracy for epoch 8: 0.12815384615384615\n----------------------------------------\nTrain Loss for epoch 9: 3.7786\nValidation Loss for epoch 9: 3.8140\nTrain Accuracy for epoch 9: 0.1681025641025641\nVal Accuracy for epoch 9: 0.13046153846153846\n----------------------------------------\nTrain Loss for epoch 10: 3.7715\nValidation Loss for epoch 10: 3.8122\nTrain Accuracy for epoch 10: 0.17502564102564103\nVal Accuracy for epoch 10: 0.13138461538461538\n----------------------------------------\nTrain Loss for epoch 11: 3.7690\nValidation Loss for epoch 11: 3.8012\nTrain Accuracy for epoch 11: 0.17743589743589744\nVal Accuracy for epoch 11: 0.14307692307692307\n----------------------------------------\nTrain Loss for epoch 12: 3.7670\nValidation Loss for epoch 12: 3.8077\nTrain Accuracy for epoch 12: 0.1785982905982906\nVal Accuracy for epoch 12: 0.13876923076923076\n----------------------------------------\nTrain Loss for epoch 13: 3.7643\nValidation Loss for epoch 13: 3.8040\nTrain Accuracy for epoch 13: 0.1830940170940171\nVal Accuracy for epoch 13: 0.14076923076923076\n----------------------------------------\nTrain Loss for epoch 14: 3.7637\nValidation Loss for epoch 14: 3.7964\nTrain Accuracy for epoch 14: 0.18234188034188034\nVal Accuracy for epoch 14: 0.14784615384615385\n----------------------------------------\nTrain Loss for epoch 15: 3.7684\nValidation Loss for epoch 15: 3.7948\nTrain Accuracy for epoch 15: 0.17731623931623933\nVal Accuracy for epoch 15: 0.1509230769230769\n----------------------------------------\nTrain Loss for epoch 16: 3.7569\nValidation Loss for epoch 16: 3.7938\nTrain Accuracy for epoch 16: 0.1894188034188034\nVal Accuracy for epoch 16: 0.1523076923076923\n----------------------------------------\nTrain Loss for epoch 17: 3.7572\nValidation Loss for epoch 17: 3.8110\nTrain Accuracy for epoch 17: 0.18945299145299146\nVal Accuracy for epoch 17: 0.134\n----------------------------------------\nTrain Loss for epoch 18: 3.7630\nValidation Loss for epoch 18: 3.7982\nTrain Accuracy for epoch 18: 0.18328205128205127\nVal Accuracy for epoch 18: 0.14876923076923076\n----------------------------------------\nTrain Loss for epoch 19: 3.7637\nValidation Loss for epoch 19: 3.8008\nTrain Accuracy for epoch 19: 0.18208547008547007\nVal Accuracy for epoch 19: 0.14323076923076922\n----------------------------------------\nTrain Loss for epoch 20: 3.7579\nValidation Loss for epoch 20: 3.8030\nTrain Accuracy for epoch 20: 0.18815384615384614\nVal Accuracy for epoch 20: 0.14415384615384616\n----------------------------------------\nTrain Loss for epoch 21: 3.7590\nValidation Loss for epoch 21: 3.8074\nTrain Accuracy for epoch 21: 0.18745299145299146\nVal Accuracy for epoch 21: 0.136\n----------------------------------------\nTrain Loss for epoch 22: 3.7614\nValidation Loss for epoch 22: 3.7958\nTrain Accuracy for epoch 22: 0.1844102564102564\nVal Accuracy for epoch 22: 0.14861538461538462\n----------------------------------------\nTrain Loss for epoch 23: 3.7720\nValidation Loss for epoch 23: 3.8025\nTrain Accuracy for epoch 23: 0.17382905982905983\nVal Accuracy for epoch 23: 0.14\n----------------------------------------\nTrain Loss for epoch 24: 3.7669\nValidation Loss for epoch 24: 3.8040\nTrain Accuracy for epoch 24: 0.17887179487179486\nVal Accuracy for epoch 24: 0.13784615384615384\n----------------------------------------\nTrain Loss for epoch 25: 3.7647\nValidation Loss for epoch 25: 3.8006\nTrain Accuracy for epoch 25: 0.18181196581196582\nVal Accuracy for epoch 25: 0.14353846153846153\n----------------------------------------\nTrain Loss for epoch 26: 3.7577\nValidation Loss for epoch 26: 3.7805\nTrain Accuracy for epoch 26: 0.18856410256410255\nVal Accuracy for epoch 26: 0.16446153846153846\n----------------------------------------\nTrain Loss for epoch 27: 3.7598\nValidation Loss for epoch 27: 3.7966\nTrain Accuracy for epoch 27: 0.1865982905982906\nVal Accuracy for epoch 27: 0.14923076923076922\n----------------------------------------\nTrain Loss for epoch 28: 3.7581\nValidation Loss for epoch 28: 3.7839\nTrain Accuracy for epoch 28: 0.1884102564102564\nVal Accuracy for epoch 28: 0.1610769230769231\n----------------------------------------\nTrain Loss for epoch 29: 3.7573\nValidation Loss for epoch 29: 3.8028\nTrain Accuracy for epoch 29: 0.1893162393162393\nVal Accuracy for epoch 29: 0.14215384615384616\n----------------------------------------\nTrain Loss for epoch 30: 3.7544\nValidation Loss for epoch 30: 3.8019\nTrain Accuracy for epoch 30: 0.1912991452991453\nVal Accuracy for epoch 30: 0.14461538461538462\n----------------------------------------\nTrain Loss for epoch 31: 3.7513\nValidation Loss for epoch 31: 3.7910\nTrain Accuracy for epoch 31: 0.19485470085470086\nVal Accuracy for epoch 31: 0.1543076923076923\n----------------------------------------\nTrain Loss for epoch 32: 3.7563\nValidation Loss for epoch 32: 3.7898\nTrain Accuracy for epoch 32: 0.1895042735042735\nVal Accuracy for epoch 32: 0.15446153846153846\n----------------------------------------\nTrain Loss for epoch 33: 3.7548\nValidation Loss for epoch 33: 3.7797\nTrain Accuracy for epoch 33: 0.19167521367521367\nVal Accuracy for epoch 33: 0.166\n----------------------------------------\nTrain Loss for epoch 34: 3.7515\nValidation Loss for epoch 34: 3.7857\nTrain Accuracy for epoch 34: 0.1946153846153846\nVal Accuracy for epoch 34: 0.15830769230769232\n----------------------------------------\nTrain Loss for epoch 35: 3.7592\nValidation Loss for epoch 35: 3.7952\nTrain Accuracy for epoch 35: 0.1868034188034188\nVal Accuracy for epoch 35: 0.1509230769230769\n----------------------------------------\nTrain Loss for epoch 36: 3.7599\nValidation Loss for epoch 36: 3.7959\nTrain Accuracy for epoch 36: 0.18528205128205127\nVal Accuracy for epoch 36: 0.14861538461538462\n----------------------------------------\nTrain Loss for epoch 37: 3.7543\nValidation Loss for epoch 37: 3.7906\nTrain Accuracy for epoch 37: 0.19174358974358974\nVal Accuracy for epoch 37: 0.1543076923076923\n----------------------------------------\nTrain Loss for epoch 38: 3.7506\nValidation Loss for epoch 38: 3.7895\nTrain Accuracy for epoch 38: 0.19538461538461538\nVal Accuracy for epoch 38: 0.15446153846153846\n----------------------------------------\nTrain Loss for epoch 39: 3.7519\nValidation Loss for epoch 39: 3.7899\nTrain Accuracy for epoch 39: 0.19405128205128205\nVal Accuracy for epoch 39: 0.15476923076923077\n----------------------------------------\nTrain Loss for epoch 40: 3.7499\nValidation Loss for epoch 40: 3.7798\nTrain Accuracy for epoch 40: 0.19586324786324785\nVal Accuracy for epoch 40: 0.16584615384615384\n----------------------------------------\nTrain Loss for epoch 41: 3.7523\nValidation Loss for epoch 41: 3.7834\nTrain Accuracy for epoch 41: 0.19302564102564101\nVal Accuracy for epoch 41: 0.16092307692307692\n----------------------------------------\nTrain Loss for epoch 42: 3.7572\nValidation Loss for epoch 42: 3.8052\nTrain Accuracy for epoch 42: 0.18871794871794872\nVal Accuracy for epoch 42: 0.14\n----------------------------------------\nTrain Loss for epoch 43: 3.7618\nValidation Loss for epoch 43: 3.7894\nTrain Accuracy for epoch 43: 0.18425641025641026\nVal Accuracy for epoch 43: 0.15584615384615386\n----------------------------------------\nTrain Loss for epoch 44: 3.7568\nValidation Loss for epoch 44: 3.7984\nTrain Accuracy for epoch 44: 0.1885128205128205\nVal Accuracy for epoch 44: 0.14584615384615385\n----------------------------------------\nTrain Loss for epoch 45: 3.7568\nValidation Loss for epoch 45: 3.7919\nTrain Accuracy for epoch 45: 0.18905982905982907\nVal Accuracy for epoch 45: 0.15307692307692308\n----------------------------------------\nTrain Loss for epoch 46: 3.7581\nValidation Loss for epoch 46: 3.7918\nTrain Accuracy for epoch 46: 0.18801709401709402\nVal Accuracy for epoch 46: 0.15353846153846154\n----------------------------------------\nTrain Loss for epoch 47: 3.7575\nValidation Loss for epoch 47: 3.7938\nTrain Accuracy for epoch 47: 0.18805128205128205\nVal Accuracy for epoch 47: 0.1503076923076923\n----------------------------------------\nTrain Loss for epoch 48: 3.7604\nValidation Loss for epoch 48: 3.7859\nTrain Accuracy for epoch 48: 0.18476923076923077\nVal Accuracy for epoch 48: 0.15876923076923077\n----------------------------------------\nTrain Loss for epoch 49: 3.7650\nValidation Loss for epoch 49: 3.7919\nTrain Accuracy for epoch 49: 0.18071794871794872\nVal Accuracy for epoch 49: 0.15353846153846154\n----------------------------------------\nTrain Loss for epoch 50: 3.7596\nValidation Loss for epoch 50: 3.7912\nTrain Accuracy for epoch 50: 0.18594871794871795\nVal Accuracy for epoch 50: 0.1533846153846154\n----------------------------------------\nTrain Loss for epoch 51: 3.7617\nValidation Loss for epoch 51: 3.7837\nTrain Accuracy for epoch 51: 0.18420512820512822\nVal Accuracy for epoch 51: 0.1610769230769231\n----------------------------------------\nTrain Loss for epoch 52: 3.7560\nValidation Loss for epoch 52: 3.7969\nTrain Accuracy for epoch 52: 0.18912820512820513\nVal Accuracy for epoch 52: 0.14723076923076922\n----------------------------------------\nTrain Loss for epoch 53: 3.7575\nValidation Loss for epoch 53: 3.7884\nTrain Accuracy for epoch 53: 0.188\nVal Accuracy for epoch 53: 0.15369230769230768\n----------------------------------------\nTrain Loss for epoch 54: 3.7594\nValidation Loss for epoch 54: 3.7943\nTrain Accuracy for epoch 54: 0.1857948717948718\nVal Accuracy for epoch 54: 0.15076923076923077\n----------------------------------------\nTrain Loss for epoch 55: 3.7732\nValidation Loss for epoch 55: 3.7857\nTrain Accuracy for epoch 55: 0.17246153846153847\nVal Accuracy for epoch 55: 0.1596923076923077\n----------------------------------------\nTrain Loss for epoch 56: 3.7666\nValidation Loss for epoch 56: 3.7970\nTrain Accuracy for epoch 56: 0.17847863247863247\nVal Accuracy for epoch 56: 0.14876923076923076\n----------------------------------------\nTrain Loss for epoch 57: 3.7643\nValidation Loss for epoch 57: 3.8012\nTrain Accuracy for epoch 57: 0.18054700854700856\nVal Accuracy for epoch 57: 0.14323076923076922\n----------------------------------------\nTrain Loss for epoch 58: 3.7630\nValidation Loss for epoch 58: 3.7945\nTrain Accuracy for epoch 58: 0.18223931623931625\nVal Accuracy for epoch 58: 0.14723076923076922\n----------------------------------------\nTrain Loss for epoch 59: 3.7574\nValidation Loss for epoch 59: 3.7914\nTrain Accuracy for epoch 59: 0.18823931623931625\nVal Accuracy for epoch 59: 0.1533846153846154\n----------------------------------------\nTrain Loss for epoch 60: 3.7580\nValidation Loss for epoch 60: 3.7966\nTrain Accuracy for epoch 60: 0.1867008547008547\nVal Accuracy for epoch 60: 0.148\n----------------------------------------\nTrain Loss for epoch 61: 3.7581\nValidation Loss for epoch 61: 3.7924\nTrain Accuracy for epoch 61: 0.18822222222222224\nVal Accuracy for epoch 61: 0.1533846153846154\n----------------------------------------\nTrain Loss for epoch 62: 3.7569\nValidation Loss for epoch 62: 3.7837\nTrain Accuracy for epoch 62: 0.18859829059829059\nVal Accuracy for epoch 62: 0.162\n----------------------------------------\nTrain Loss for epoch 63: 3.7558\nValidation Loss for epoch 63: 3.7914\nTrain Accuracy for epoch 63: 0.19005128205128205\nVal Accuracy for epoch 63: 0.1529230769230769\n----------------------------------------\nTrain Loss for epoch 64: 3.7614\nValidation Loss for epoch 64: 3.7914\nTrain Accuracy for epoch 64: 0.18417094017094018\nVal Accuracy for epoch 64: 0.15307692307692308\n----------------------------------------\nTrain Loss for epoch 65: 3.7597\nValidation Loss for epoch 65: 3.7875\nTrain Accuracy for epoch 65: 0.1863076923076923\nVal Accuracy for epoch 65: 0.158\n----------------------------------------\nTrain Loss for epoch 66: 3.7594\nValidation Loss for epoch 66: 3.8075\nTrain Accuracy for epoch 66: 0.18654700854700854\nVal Accuracy for epoch 66: 0.1356923076923077\n----------------------------------------\nTrain Loss for epoch 67: 3.7658\nValidation Loss for epoch 67: 3.7961\nTrain Accuracy for epoch 67: 0.17941880341880342\nVal Accuracy for epoch 67: 0.14707692307692308\n----------------------------------------\nTrain Loss for epoch 68: 3.7693\nValidation Loss for epoch 68: 3.8093\nTrain Accuracy for epoch 68: 0.17576068376068377\nVal Accuracy for epoch 68: 0.1356923076923077\n----------------------------------------\nTrain Loss for epoch 69: 3.7679\nValidation Loss for epoch 69: 3.8015\nTrain Accuracy for epoch 69: 0.17776068376068377\nVal Accuracy for epoch 69: 0.14246153846153847\n----------------------------------------\nTrain Loss for epoch 70: 3.7660\nValidation Loss for epoch 70: 3.8017\nTrain Accuracy for epoch 70: 0.17892307692307693\nVal Accuracy for epoch 70: 0.14446153846153847\n----------------------------------------\nTrain Loss for epoch 71: 3.7642\nValidation Loss for epoch 71: 3.8020\nTrain Accuracy for epoch 71: 0.18117948717948718\nVal Accuracy for epoch 71: 0.14307692307692307\n----------------------------------------\nTrain Loss for epoch 72: 3.7713\nValidation Loss for epoch 72: 3.8035\nTrain Accuracy for epoch 72: 0.17398290598290597\nVal Accuracy for epoch 72: 0.1416923076923077\n----------------------------------------\nTrain Loss for epoch 73: 3.7750\nValidation Loss for epoch 73: 3.8005\nTrain Accuracy for epoch 73: 0.17066666666666666\nVal Accuracy for epoch 73: 0.14553846153846153\n----------------------------------------\nTrain Loss for epoch 74: 3.7714\nValidation Loss for epoch 74: 3.7935\nTrain Accuracy for epoch 74: 0.1744273504273504\nVal Accuracy for epoch 74: 0.15153846153846154\n----------------------------------------\nTrain Loss for epoch 75: 3.7653\nValidation Loss for epoch 75: 3.8011\nTrain Accuracy for epoch 75: 0.18027350427350428\nVal Accuracy for epoch 75: 0.14307692307692307\n----------------------------------------\nTrain Loss for epoch 76: 3.7707\nValidation Loss for epoch 76: 3.8047\nTrain Accuracy for epoch 76: 0.1744102564102564\nVal Accuracy for epoch 76: 0.13938461538461538\n----------------------------------------\nTrain Loss for epoch 77: 3.7765\nValidation Loss for epoch 77: 3.8074\nTrain Accuracy for epoch 77: 0.169008547008547\nVal Accuracy for epoch 77: 0.13615384615384615\n----------------------------------------\nTrain Loss for epoch 78: 3.7713\nValidation Loss for epoch 78: 3.7994\nTrain Accuracy for epoch 78: 0.17323076923076924\nVal Accuracy for epoch 78: 0.144\n----------------------------------------\nTrain Loss for epoch 79: 3.7696\nValidation Loss for epoch 79: 3.7961\nTrain Accuracy for epoch 79: 0.17541880341880342\nVal Accuracy for epoch 79: 0.14907692307692308\n----------------------------------------\nTrain Loss for epoch 80: 3.7653\nValidation Loss for epoch 80: 3.8036\nTrain Accuracy for epoch 80: 0.17998290598290598\nVal Accuracy for epoch 80: 0.14092307692307693\n----------------------------------------\nTrain Loss for epoch 81: 3.7639\nValidation Loss for epoch 81: 3.7843\nTrain Accuracy for epoch 81: 0.18094017094017095\nVal Accuracy for epoch 81: 0.16123076923076923\n----------------------------------------\nTrain Loss for epoch 82: 3.7616\nValidation Loss for epoch 82: 3.7955\nTrain Accuracy for epoch 82: 0.18388034188034189\nVal Accuracy for epoch 82: 0.14907692307692308\n----------------------------------------\nTrain Loss for epoch 83: 3.7645\nValidation Loss for epoch 83: 3.7935\nTrain Accuracy for epoch 83: 0.18100854700854702\nVal Accuracy for epoch 83: 0.1513846153846154\n----------------------------------------\nTrain Loss for epoch 84: 3.7670\nValidation Loss for epoch 84: 3.7866\nTrain Accuracy for epoch 84: 0.1776068376068376\nVal Accuracy for epoch 84: 0.158\n----------------------------------------\nTrain Loss for epoch 85: 3.7649\nValidation Loss for epoch 85: 3.7970\nTrain Accuracy for epoch 85: 0.17982905982905983\nVal Accuracy for epoch 85: 0.14753846153846153\n----------------------------------------\nTrain Loss for epoch 86: 3.7689\nValidation Loss for epoch 86: 3.8003\nTrain Accuracy for epoch 86: 0.17615384615384616\nVal Accuracy for epoch 86: 0.1413846153846154\n----------------------------------------\nTrain Loss for epoch 87: 3.7795\nValidation Loss for epoch 87: 3.7920\nTrain Accuracy for epoch 87: 0.16514529914529916\nVal Accuracy for epoch 87: 0.15123076923076922\n----------------------------------------\nTrain Loss for epoch 88: 3.7775\nValidation Loss for epoch 88: 3.7993\nTrain Accuracy for epoch 88: 0.1674188034188034\nVal Accuracy for epoch 88: 0.1456923076923077\n----------------------------------------\nTrain Loss for epoch 89: 3.7734\nValidation Loss for epoch 89: 3.7946\nTrain Accuracy for epoch 89: 0.17148717948717948\nVal Accuracy for epoch 89: 0.14969230769230768\n----------------------------------------\nTrain Loss for epoch 90: 3.7711\nValidation Loss for epoch 90: 3.7886\nTrain Accuracy for epoch 90: 0.17364102564102565\nVal Accuracy for epoch 90: 0.15661538461538463\n----------------------------------------\nTrain Loss for epoch 91: 3.7709\nValidation Loss for epoch 91: 3.7958\nTrain Accuracy for epoch 91: 0.1737948717948718\nVal Accuracy for epoch 91: 0.14876923076923076\n----------------------------------------\nTrain Loss for epoch 92: 3.7739\nValidation Loss for epoch 92: 3.8168\nTrain Accuracy for epoch 92: 0.17112820512820512\nVal Accuracy for epoch 92: 0.12753846153846154\n----------------------------------------\nTrain Loss for epoch 93: 3.7981\nValidation Loss for epoch 93: 3.8203\nTrain Accuracy for epoch 93: 0.14675213675213675\nVal Accuracy for epoch 93: 0.12261538461538461\n----------------------------------------\nTrain Loss for epoch 94: 3.8065\nValidation Loss for epoch 94: 3.8163\nTrain Accuracy for epoch 94: 0.1376923076923077\nVal Accuracy for epoch 94: 0.12646153846153846\n----------------------------------------\nTrain Loss for epoch 95: 3.7967\nValidation Loss for epoch 95: 3.8110\nTrain Accuracy for epoch 95: 0.148017094017094\nVal Accuracy for epoch 95: 0.1336923076923077\n----------------------------------------\nTrain Loss for epoch 96: 3.7873\nValidation Loss for epoch 96: 3.8099\nTrain Accuracy for epoch 96: 0.15716239316239317\nVal Accuracy for epoch 96: 0.13307692307692306\n----------------------------------------\nTrain Loss for epoch 97: 3.7881\nValidation Loss for epoch 97: 3.7976\nTrain Accuracy for epoch 97: 0.15601709401709402\nVal Accuracy for epoch 97: 0.14707692307692308\n----------------------------------------\nTrain Loss for epoch 98: 3.7888\nValidation Loss for epoch 98: 3.8078\nTrain Accuracy for epoch 98: 0.15593162393162394\nVal Accuracy for epoch 98: 0.1363076923076923\n----------------------------------------\nTrain Loss for epoch 99: 3.7869\nValidation Loss for epoch 99: 3.8032\nTrain Accuracy for epoch 99: 0.15777777777777777\nVal Accuracy for epoch 99: 0.14153846153846153\n----------------------------------------\nTrain Loss for epoch 100: 3.7807\nValidation Loss for epoch 100: 3.8064\nTrain Accuracy for epoch 100: 0.16384615384615384\nVal Accuracy for epoch 100: 0.13723076923076924\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}